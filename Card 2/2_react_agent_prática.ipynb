{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalação e importações necessárias"
      ],
      "metadata": {
        "id": "liMl82dZEUFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsfHlc4Nlx5C",
        "outputId": "4d3b6888-acc7-4906-ea54-b236d3e660f9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "64nOnNxSpTIh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GROQ_API_KEY'] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando o funcionamento da API do Groq"
      ],
      "metadata": {
        "id": "-9I2pnqqEkLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-70b-8192\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mKxn285meZe",
        "outputId": "c2ec7a3d-f11d-4a1c-f1f9-f3b1c5ec436c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models are crucial in today's natural language processing (NLP) landscape, and their importance can be seen in several aspects:\n",
            "\n",
            "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation systems to respond quickly and efficiently. This is particularly important in customer-facing applications where delayed responses can lead to frustration and a negative user experience.\n",
            "2. **Low-Latency Inference**: Fast language models can perform inference (i.e., make predictions or generate text) rapidly, which is essential for applications that require immediate responses, such as:\n",
            "\t* Sentiment analysis for social media monitoring\n",
            "\t* Text classification for spam detection\n",
            "\t* Language translation for real-time communication\n",
            "3. **Scalability**: Fast language models can handle large volumes of data and scale to meet the demands of large-scale applications, such as:\n",
            "\t* Processing large datasets for data analysis and insights\n",
            "\t* Handling high traffic volumes in web applications\n",
            "\t* Supporting massive language models with billions of parameters\n",
            "4. **Energy Efficiency**: Fast language models can reduce energy consumption and carbon footprint, which is critical for environmentally friendly and sustainable AI systems. This is particularly important for large-scale data centers and cloud computing infrastructure.\n",
            "5. **Edge AI**: Fast language models can be deployed on edge devices, such as smartphones, smart home devices, and autonomous vehicles, enabling real-time processing and reducing latency. This is essential for applications that require immediate processing and decision-making, such as:\n",
            "\t* Voice assistants on smart speakers\n",
            "\t* Object detection in autonomous vehicles\n",
            "\t* Real-time language translation on mobile devices\n",
            "6. **Improved User Experience**: Fast language models can provide a more seamless and responsive user experience, leading to increased user engagement and satisfaction. This is particularly important for applications that require interactive and dynamic responses, such as:\n",
            "\t* Conversational AI for customer support\n",
            "\t* Language-based games and interactive stories\n",
            "\t* Real-time language translation for travel and tourism\n",
            "7. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling researchers to experiment and iterate faster, and explore new ideas and applications more efficiently.\n",
            "8. **Cost Savings**: Fast language models can reduce computational costs and infrastructure expenses, making it more economical to develop and deploy NLP applications.\n",
            "9. **Competitive Advantage**: Fast language models can provide a competitive advantage in industries where speed and responsiveness are critical, such as customer service, finance, and healthcare.\n",
            "10. **Future-Proofing**: Fast language models can future-proof NLP applications, enabling them to adapt to emerging trends and technologies, such as edge AI, 5G networks, and the Internet of Things (IoT).\n",
            "\n",
            "In summary, fast language models are essential for building responsive, scalable, and efficient NLP applications that can provide a better user experience, reduce costs, and drive innovation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando a classe Agente"
      ],
      "metadata": {
        "id": "1MKwLt4YEuwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "o método init recebe uma instância da API (cliente) e uma mensagem de sistema opcional, depois armazena ambos como atributos e cria uma lista para armazenar o histórico de mensagens\n",
        "\n",
        "o método call recebe uma mensagem do usuário e adiciona ao histórico, chamando o método execute para obter uma resposta e, adiciona a resposta ao histórico de mensagem, retornando ela\n",
        "\n",
        "por fim, o método execute envia o histórico de mensagens pra API do modelo, além de extrair e retornar o conteúdo da resposta gerada"
      ],
      "metadata": {
        "id": "VlhEqCuCMgwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
        "        self.client = client\n",
        "        self.system = system\n",
        "        self.messages: list = []\n",
        "        if self.system:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "    def __call__(self, message=\"\"):\n",
        "        if message:\n",
        "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        result = self.execute()\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "        return result\n",
        "\n",
        "    def execute(self):\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"llama3-70b-8192\", messages=self.messages\n",
        "        )\n",
        "        return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "O3Zl2rqgv-0Q"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo o Prompt"
      ],
      "metadata": {
        "id": "OVOHOv71NsO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eu adicionei novas funções (que serão explicadas na próxima célula) para aumentar a potencia do agente e, claro, para que eu tenha um aprendizado mais completo"
      ],
      "metadata": {
        "id": "wAMHLMs9OTB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer.\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "Your available actions are:\n",
        "\n",
        "calculate:\n",
        "e.g. calculate: 4 * 7 / 3\n",
        "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "\n",
        "get_planet_mass:\n",
        "e.g. get_planet_mass: Earth\n",
        "returns mass of the planet in kg\n",
        "\n",
        "get_planet_gravity:\n",
        "e.g. get_planet_gravity: Mars\n",
        "returns the surface gravity of the planet in m/s² and how it compares to Earth\n",
        "\n",
        "get_planet_temperature:\n",
        "e.g. get_planet_temperature: Mars\n",
        "returns average, minimum and maximum temperature of the planet in Celsius\n",
        "\n",
        "Example session:\n",
        "\n",
        "Question: What is the mass of Earth times 2?\n",
        "Thought: I need to find the mass of Earth\n",
        "Action: get_planet_mass: Earth\n",
        "PAUSE\n",
        "\n",
        "Observation: 5.972e24\n",
        "\n",
        "Thought: I need to multiply this by 2\n",
        "Action: calculate: 5.972e24 * 2\n",
        "PAUSE\n",
        "\n",
        "Observation: 1.1944e+25\n",
        "\n",
        "Answer: The mass of Earth times 2 is 1.1944e+25 kg.\n",
        "\n",
        "Now it's your turn:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "uWjHjbieyuST"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo as funções do Agente"
      ],
      "metadata": {
        "id": "iWz6prGNP9Dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a calculte receberá uma string de uma operação matemática e através da função e val vai retornar o resultado\n",
        "\n",
        "já a get_planet_mass receberá o nome de um planeta como entrada e retornar a sua massa em kg, mas através de notação científica"
      ],
      "metadata": {
        "id": "OBSHO5SiQdLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate(operation: str) -> float:\n",
        "    return eval(operation)\n",
        "\n",
        "\n",
        "def get_planet_mass(planet) -> float:\n",
        "    match planet.lower():\n",
        "        case \"earth\":\n",
        "            return 5.972e24\n",
        "        case \"jupiter\":\n",
        "            return 1.898e27\n",
        "        case \"mars\":\n",
        "            return 6.39e23\n",
        "        case \"mercury\":\n",
        "            return 3.285e23\n",
        "        case \"neptune\":\n",
        "            return 1.024e26\n",
        "        case \"saturn\":\n",
        "            return 5.683e26\n",
        "        case \"uranus\":\n",
        "            return 8.681e25\n",
        "        case \"venus\":\n",
        "            return 4.867e24\n",
        "        case _:\n",
        "            return 0.0"
      ],
      "metadata": {
        "id": "kJxCgYSKOMFF"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções novas adicionadas por mim"
      ],
      "metadata": {
        "id": "aJxfAcLBLMqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_planet_gravity recebe o nome de um planeta e retorna a gravidade da sua superfície, em m/s² e compara com a da terra\n",
        "\n",
        "get_planet_temperature recebe o nome de um planeta e retorna a temperatura mínima, máxima e média em graus Celsius"
      ],
      "metadata": {
        "id": "BBbaHNSaWJBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_planet_gravity(planet: str) -> str:\n",
        "    gravity_data = {\n",
        "        \"mercury\": {\"gravity\": 3.7, \"compared_to_earth\": \"38% of Earth\"},\n",
        "        \"venus\": {\"gravity\": 8.87, \"compared_to_earth\": \"90% of Earth\"},\n",
        "        \"earth\": {\"gravity\": 9.81, \"compared_to_earth\": \"reference (100%)\"},\n",
        "        \"mars\": {\"gravity\": 3.71, \"compared_to_earth\": \"38% of Earth\"},\n",
        "        \"jupiter\": {\"gravity\": 24.79, \"compared_to_earth\": \"253% of Earth\"},\n",
        "        \"saturn\": {\"gravity\": 10.44, \"compared_to_earth\": \"106% of Earth\"},\n",
        "        \"uranus\": {\"gravity\": 8.87, \"compared_to_earth\": \"90% of Earth\"},\n",
        "        \"neptune\": {\"gravity\": 11.15, \"compared_to_earth\": \"114% of Earth\"}\n",
        "    }\n",
        "\n",
        "    planet = planet.lower().strip()\n",
        "    if planet in gravity_data:\n",
        "        data = gravity_data[planet]\n",
        "        return f\"Gravity in {planet.capitalize()}: {data['gravity']} m/s² ({data['compared_to_earth']}).\"\n",
        "    else:\n",
        "        return f\"Gravity data not available for '{planet}'.\"\n",
        "\n",
        "\n",
        "def get_planet_temperature(planet: str) -> str:\n",
        "    planet_temps = {\n",
        "        \"mercury\": {\"min\": -173, \"max\": 427, \"avg\": 167, \"desc\": \"extremely variable due to lack of atmosphere\"},\n",
        "        \"venus\": {\"min\": 462, \"max\": 462, \"avg\": 462, \"desc\": \"nearly uniform due to dense atmosphere\"},\n",
        "        \"earth\": {\"min\": -89, \"max\": 56, \"avg\": 15, \"desc\": \"habitable, with variations by region and season\"},\n",
        "        \"mars\": {\"min\": -153, \"max\": 20, \"avg\": -63, \"desc\": \"with large daily and seasonal variations\"},\n",
        "        \"jupiter\": {\"min\": -145, \"max\": -145, \"avg\": -145, \"desc\": \"relatively constant in the upper layers\"},\n",
        "        \"saturn\": {\"min\": -178, \"max\": -178, \"avg\": -178, \"desc\": \"cold and constant in the upper layers\"},\n",
        "        \"uranus\": {\"min\": -224, \"max\": -224, \"avg\": -224, \"desc\": \"extremely cold and uniform\"},\n",
        "        \"neptune\": {\"min\": -218, \"max\": -218, \"avg\": -218, \"desc\": \"very cold with occasional thunderstorms\"}\n",
        "    }\n",
        "\n",
        "    planet = planet.lower().strip()\n",
        "    if planet in planet_temps:\n",
        "        data = planet_temps[planet]\n",
        "        return f\"Temperature for {planet.capitalize()}: Average of {data['avg']}°C (min: {data['min']}°C, max: {data['max']}°C). {data['desc'].capitalize()}.\"\n",
        "    else:\n",
        "        return f\"No temperature data available for '{planet}'.\""
      ],
      "metadata": {
        "id": "sDe-CO3xLW-Q"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execução do Agente com loop"
      ],
      "metadata": {
        "id": "wc04w0t1URj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a função agent_loop automatiza o ciclo, recebendo as iterações, o prompt e a pergunta inicial\n",
        "\n",
        "o loop principal incrementa o contador de iterações, envia o prompt atual ao agente e imprime sua resposta se a resposta contém PAUSE ou ACTION, é extraído o nome da ferramenta e o argumento se ele for válido, executa a função e prepara a observação\n",
        "\n",
        "caso a resposta contenha ANSWER, encerra o loop, visto que está definido que seria a resposta final"
      ],
      "metadata": {
        "id": "-5mLqCvwYZpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def agent_loop(max_iterations, system, query):\n",
        "    agent = Agent(client=client, system=system_prompt)\n",
        "    tools = [\"calculate\", \"get_planet_mass\", \"get_planet_gravity\", \"get_planet_temperature\"]\n",
        "    next_prompt = query\n",
        "    i = 0\n",
        "    while i < max_iterations:\n",
        "        i += 1\n",
        "        result = agent(next_prompt)\n",
        "        print(result)\n",
        "\n",
        "        if \"PAUSE\" in result and \"Action\" in result:\n",
        "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
        "            chosen_tool = action[0][0]\n",
        "            arg = action[0][1]\n",
        "\n",
        "            if chosen_tool in tools:\n",
        "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
        "                next_prompt = f\"Observation: {result_tool}\"\n",
        "\n",
        "            else:\n",
        "                next_prompt = \"Observation: Tool not found\"\n",
        "\n",
        "            print(next_prompt)\n",
        "            continue\n",
        "\n",
        "        if \"Answer\" in result:\n",
        "            break"
      ],
      "metadata": {
        "id": "_9WvU1MI32T4"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_loop(10, system = system_prompt, query=\"If I weigh 75 kg on Earth, how much would I weigh on Mars and Jupiter?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeHlHA3SX5kT",
        "outputId": "3b1c44c0-e696-4864-c905-e4c81f20bf1c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find the surface gravity of Mars and Jupiter to calculate my weight on those planets.\n",
            "\n",
            "Action: get_planet_gravity: Mars\n",
            "PAUSE\n",
            "Observation: Gravity in Mars: 3.71 m/s² (38% of Earth).\n",
            "Thought: I now have the surface gravity of Mars, but I also need the surface gravity of Jupiter. \n",
            "\n",
            "Action: get_planet_gravity: Jupiter\n",
            "PAUSE\n",
            "Observation: Gravity in Jupiter: 24.79 m/s² (253% of Earth).\n",
            "Thought: I now have the surface gravity of both Mars and Jupiter. I need to calculate my weight on these planets. \n",
            "\n",
            "Action: calculate: 75 * (3.71 / 9.81)\n",
            "PAUSE\n",
            "Observation: 28.363914373088686\n",
            "Thought: I have now calculated my weight on Mars. I need to calculate my weight on Jupiter.\n",
            "\n",
            "Action: calculate: 75 * (24.79 / 9.81)\n",
            "PAUSE\n",
            "Observation: 189.52599388379204\n",
            "Thought: I have now calculated my weight on both Mars and Jupiter.\n",
            "\n",
            "Answer: If I weigh 75 kg on Earth, I would weigh approximately 28.36 kg on Mars and approximately 189.53 kg on Jupiter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_loop(10, system = system_prompt, query=\"What is the average temperature difference between Mars and Venus?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUZRP1MRYHcl",
        "outputId": "34da6ce7-a28a-4bdb-92d4-3e5c00a9f429"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find the average temperatures of Mars and Venus.\n",
            "Thought: I need to find the average temperatures of Mars and Venus.\n",
            "Action: get_planet_temperature: Mars\n",
            "PAUSE\n",
            "Observation: Temperature for Mars: Average of -63°C (min: -153°C, max: 20°C). With large daily and seasonal variations.\n",
            "Thought: Now I have the temperature of Mars. I need to get the temperature of Venus.\n",
            "Action: get_planet_temperature: Venus\n",
            "PAUSE\n",
            "Observation: Temperature for Venus: Average of 462°C (min: 462°C, max: 462°C). Nearly uniform due to dense atmosphere.\n",
            "Thought: Now I have the temperatures of both Mars and Venus. I need to calculate the difference in average temperatures.\n",
            "Action: calculate: 462 - (-63)\n",
            "PAUSE\n",
            "Observation: 525\n",
            "Thought: I have calculated the average temperature difference between Mars and Venus.\n",
            "Answer: The average temperature difference between Mars and Venus is 525°C.\n"
          ]
        }
      ]
    }
  ]
}